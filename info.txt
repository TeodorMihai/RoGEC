typo generator:
    https://github.com/wsong/Typo-Distance/blob/master/typodistance.py
    -based on Knuth algorithm
    -insertion more likely than deletion

from andrew paper:
    -rare words?
    -word level nn with fixed vocabulary - poorly suited for oov (years)
    -character level works because you only need to copy inpuut -> output (attention si crucial + pyramid structure)
    -combine with a language model (reranker)
    -controlling precision: 
    -multiple way to correct a sentence -> blue not accuracy
    -synthetic errors:  article or determiner errors and noun number errors
    -rich morpholofy -> character levels
    -evaluated on how well its proposed corrections or edits match the gold-standard edits
    -scores for n-grams to detect errors

abbraviations:
    WMT: workshop machien translation
    LM: lamguage model
    NMT: Neural Machine Translation


datasets:
        Corpus          #sent pair    mentions
        WMT News crawl  100M english  also for ro         
        Gutenberg       11.6M         0 ann
        Tatoeba         1.17M         0 ann
        WikiText-103    3.93M         0 ann
        Lang-8          1,114,139     1-8
        CLC             1,366,075     1/private
        NUCLE           57,119        1  
        Extended Lang-8 2,865,639     1 
        FCE             33,200        1
        W&I Train       34,308        1 annotations
        W&I+LOCNESS Dev 4,384         1 annotations
        W&I+L-Test      4,480         5 ANNOT

challanges:
    CoNLL-2014 Shared Task - eval on NUCLE corpus (+10 annotations) + M^2
    JFLEG: 700 sents - GLEU
    BEA: (eval with ERRANT) 
        unrestricted:   proprietary  & all u want
        restricted:     only on FCE, Lang-8, NUCLE, W&I+LOCNESS, NO parallel
        low resource:   only W&I+LOCNESS dev set (no other datatset) but  parallel is fine (wiki)

papers:
    BEA:
        low resource:
            Neural Grammatical Error Correction Systems with UnsupervisedPre-training on Synthetic Data:
                -Microsoft: Roman Grundkiewicz, Marcin Junczys-Dowmunt, Kenneth Heafield†:
                -synthetic data: replace words with confusions sets, constructing confusions set with spellchekers
                        +swapping, deleting words + wikipedia edits 
                -spellchecker based replacing works better than word embeddings or Levensthein dist
                -very detailed work on the model & other stuff (transfformer)
                Interestingly, the performance of restricted and low-resourcse systems on native texts is identical
            The LAIX Systems in the BEA-2019 GEC Shared Task
                -Ruobing Li, Chuan Wang, Yefei Zha, Yonghong Yu, Shiman Guo, Qiang Wang, Yang Liu† Hui Lin†
                -combine classifiers, rules, spell checker and NMT model -> solver 
                -for some error types classfiers trained on NATIVE text have good performance 
                    (labels for each classificator depends on part-of-speech tags)
                    -classifiers (fixed labels nr):
                        -7 error types: subj-ver agr, prep subst, missing comma, verb form 
                        -for word form use the pointer context model (interesting diff labels for each word)
                -for NMT use wiki ed
            Weakly Supervised Grammatical Error Correction using Iterative Decoding
                -Google: Jared Lichtarge, Christopher Alberti, Shankar Kumar, Noam Shazeer, Niki Parmar
                -wikipedia + random char errors only (incremental decoding)
                -after training only on wikipedia, continue to train on Lang 8 corous
            !!A Neural Grammatical Error Correction System Built On Better Pre-training and Sequential Transfer Learning
                Yo Joong Choe, Kakao company, Jiyeon Ham*
                -To tackle this challenge, we first generate erroneous versions of large unannotated corpora using a realistic
                     noising function. The resulting parallel corpora are subsequently used to pre-train Transformer models.
                    Then, by sequentially applying transfer
                    learning, we adapt these models to the domain and style of the test set

    
how to annotate:
    1. categories - mandatory - how to define them - diacritics vs spelling
    2. classify proficeny of the writer (maybe grade?) 
    3. tool - see NUCLE corpus
        3. select span (minimum that defines the error) -> correct (can overlap)
            (e annotators were asked to select the minimal text span so that minimal changes were made to
                arrive at the corrected text.)


stats CNA:

    phrases:
        del:
            multor șlagăre	popular/cântecelor populare și al șlagărelor	sintaxă	Sintaxă: Dezacord al articolului genitival.
            o poză șocantă, dezvăluită recent	o poză șocantă, apărută recent	other	semantică
            un avion Airbus cu peste 149 de pasageri la bord	un avion Airbus cu 149 de pasageri la bord	semantică	Semantică: Formulare ilogică avionul avea exact 149 de pasageri.
            dar o întrebare pentru doamna Iolanda?	dar o întrebare pentru doamna Iolanda Balaș?	stilistică	Stilistică: Adresarea sau referirea la o persoană doar prin numele mic, chiar și precedat de doamna, domnul(e), are un grad de politețe redus.

        duplicates:
            economist șef BNR	economist-șef la/al BNR	ortografie
            Uită-te la emisiunea unui nord-vestist /	Uită-te la emisiunea unui prezentator nord-vestic
            discuțiile pe titularizare dezbaterile pe legea învățământului	discuțiile despre titularizare/privind titularizarea dezbaterile privind legea învățământului	sintaxă	Sintaxă: folosirea inadecvată a prepoziției pe.
            proprietar mașină	proprietar al mașinii / proprietarul mașinii	sintaxă	Sintaxă: Nemarcarea relației sintactice.	
        stats:
            inital: 3386
            INFO:root:duplicates wrong: 32
            INFO:root:duplicates pairs (eliminated): 213
            INFO:root:same wrong/correct: 53
            INFO:root:stats per type: {'sintaxă': 1023, 'ortografie': 1149, 'punctuație': 122, 'semantică': 104, 'lexic': 116, 'stilistică': 18, 'other': 107}
            INFO:root:average nr tokens wrong samples 10.052631578947368
            INFO:root:average nr tokens correct samples 9.777777777777779
    sent:
        del:
            Cine e Badea...s-a inflamat orezul, grișul în el?	[reformulare] Cine se crede Badea?	stilistică	Stilistică: exprimare nereverențioasă în citarea unor posibili comentatori la adresa prezentatorului.
            Când apare un analist la televizor, toată lumea pune botu’	Când apare un analist la televizor, toată lumea îl crede	stilistică	Stilistică
            autocarul a părăsit șoseaua și s-a prăbușit într-o regiune stâncoasă	sugestie: într-o regiune stâncoasă, autocarul a părăsit șoseaua și s-a prăbușit în gol [după cum se vede în imagini]	lexic	lexic (regiune = întindere mare de pământ mai mult sau mai puțin omogenă, dintr-o țară sau de pe glob, care prezintă caractere comune; ținut, zonă.“, DEX)
            mascota emisiunii noastre ... [celălalt prezentator:] să- l ducem la ...	mascota emisiunii noastre ... [celălalt prezentator:] s-o ducem la ...	sintaxă	sintaxă: Dezacord.
            Patru cadavre au fost descoperite la locul cadavrei	Patru cadavre au fost descoperite la locul exploziei	other	Rostire accidentală, necorectată
            Ceea ce însă a lipsit de 1 Mai 2010 în Vama Veche	Ceea ce va lipsi însă de 1 Mai 2010 în Vama Veche	semantică	Semantică: Transmisiunea se face la data de 30 aprilie, care precedă data de 1 Mai. De aceea, folosirea timpului trecut nu este justificată.
            Cumpărătorii au fost încântați mai ales datorită faptului că au economisit până la 200 de lei dacă alegeau să cumpere din librării.	Cumpărătorii au fost încântați mai ales că au economisit până la 200 de lei, fapt care nu s-ar fi întâmplat dacă ar fi ales să cumpere din librării.	sintaxă	Sintaxă, semantică: Construcție defectuoasă a enunțului.
            Hai mă, ... Îi place mă,...	Hai, mă, ... Îi place, mă,...	punctuație	Punctuație: Absența virgulei care separă interjecția de restul enunțului.
            Vă reamintesc, la ora 19 și 30 de minute, declarație președintele Traian Băsescu	Vă reamintesc, la ora 19 și 30 de minute, vom transmite declarația președintelui Traian Băsescu	sintaxă	Sintaxă: Nemarcarea realațiilor sintactice dintre cuvinte.
            Leonard Cohen... va prezenta primul său	Leonard Cohen... va face primul său	semantică	Semantică: verbul a prezenta este nepotrivit contextual (alunecare
            și, mai ales, vor avea parte și de a se bucura de un concert de muzică în cinstea lor, pentru că azi este ziua lor	și, mai ales, vor avea parte de un concert în cinstea lor	semantică	Semantică: Enunț redundant din punct de vedere semantic.
            ...de comportamentul riscant al domnului Strauss-Kahn (par le comportement scabreux de Monsieur Strauss-Kahn)	...de comportamentul imoral/ reprobabil/ indecent al domnului Strauss-Kahn	semantică	Semantică: Traducere inexactă a unei declarații.
            Prognoză România, la noapte Prognoză București	Prognoză pentru România, la noapte Prognoză pentru București	sintaxă	Sintaxă: Nemarcarea relațiilor sintactice.
            N-a excelat în a promite foarte mult	Nu s-a hazardat să promită foarte mult	semantică	Semantică: Folosire improprie a verbului a excela.
            O gara plină de indivizi suspecți; așa-i în gară, întotdeauna. În gară e un loc suspect (?Ramon Cotizo)	O gara plină de indivizi suspecți; așa-i în gară întotdeauna. Gara e un loc suspect
            Care-i maximu’ de ani care ai K l-ai sta în închisoare?	nu știu, de foame, după fete
            Om vedea de unde o să luați banii	Nu se știe de unde o să luați banii
        stats:
            initial: 5500
            INFO:root:duplicates wrong: 62
            INFO:root:duplicates pairs (eliminated): 71
            INFO:root:same wrong/correct: 145
            INFO:root:stats per type: {'sintaxă': 1860, 'ortografie': 1098, 'punctuație': 467, 'semantică': 399, 'lexic': 217, 'stilistică': 53, 'other': 381}  
            INFO:root:average nr tokens wrong samples 19.81578947368421
            INFO:root:average nr tokens correct samples 20.62162162162162


ERRANT:
    run errant:
        python3 parallel_to_m2.py -orig ../corpora/errant_sent_original.txt  -cor ../corpora/errant_sent_corrected.txt -out ../corpora/out.txt